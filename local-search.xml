<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>常用命令汇总</title>
    <link href="/2020/09/24/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <url>/2020/09/24/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="其它命令"><a href="#其它命令" class="headerlink" title="其它命令"></a>其它命令</h2><h3 id="【markdown代码折叠】"><a href="#【markdown代码折叠】" class="headerlink" title="【markdown代码折叠】"></a>【markdown代码折叠】</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">details</span>&gt;</span></span><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">summary</span>&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">b</span>&gt;</span></span>点击查看完整代码<span class="xml"><span class="hljs-tag">&lt;/<span class="hljs-name">b</span>&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;/<span class="hljs-name">summary</span>&gt;</span></span><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">pre</span>&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">code</span>&gt;</span></span><br><span class="xml"><span class="hljs-tag">&lt;/<span class="hljs-name">code</span>&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;/<span class="hljs-name">pre</span>&gt;</span></span><br><span class="xml"><span class="hljs-tag">&lt;/<span class="hljs-name">details</span>&gt;</span></span><br></code></pre></td></tr></table></figure><h3 id="免秘钥登录"><a href="#免秘钥登录" class="headerlink" title="免秘钥登录"></a>免秘钥登录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa<br>ssh-copy-id node1<br>scp /root/.ssh/authorized_keys node2:/root/.ssh<br>scp /root/.ssh/authorized_keys node3:/root/.ssh<br></code></pre></td></tr></table></figure><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="【启动hive的metastore、hiveserver2服务】"><a href="#【启动hive的metastore、hiveserver2服务】" class="headerlink" title="【启动hive的metastore、hiveserver2服务】"></a>【启动hive的metastore、hiveserver2服务】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HIVE_HOME=/<span class="hljs-built_in">export</span>/server/hive-2.1.0<br>nohup /<span class="hljs-built_in">export</span>/server/hive-2.1.0/bin/hive --service metastore   &amp;<br>nohup /<span class="hljs-built_in">export</span>/server/hive-2.1.0/bin/hiveserver2 start &amp;<br>【hive元数据初始化和更新】<br>schematool -dbType mysql -initSchema<br>schematool -dbType mysql -upgradeSchema<br></code></pre></td></tr></table></figure><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="【重新启动zk和kafka】"><a href="#【重新启动zk和kafka】" class="headerlink" title="【重新启动zk和kafka】"></a>【重新启动zk和kafka】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">zkServer.sh stop <br>kafka-server-stop.sh <br>zkServer.sh start <br>nohup /<span class="hljs-built_in">export</span>/server/kafka/bin/kafka-server-start.sh /<span class="hljs-built_in">export</span>/server/kafka/config/server.properties &amp;<br><br>【启动kafka服务】<br>启动Zookeeper 服务<br>zookeeper-daemon.sh start<br>启动Kafka 服务<br>kafka-daemon.sh start<br><br></code></pre></td></tr></table></figure><h3 id="【彻底删除kafka主题】"><a href="#【彻底删除kafka主题】" class="headerlink" title="【彻底删除kafka主题】"></a>【彻底删除kafka主题】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-topics.sh --zookeeper node3:2181 --list <br>kafka-topics.sh --zookeeper node3:2181 --delete --topic spark_kafka<br><br>【zkCli.sh】<br>ls /config/topics<br>rmr /config/topics/spark_kafka<br>rmr /brokers/topics/spark_kafka<br>rmr /admin/delete_topics/spark_kafka<br></code></pre></td></tr></table></figure><h3 id="【创建主题】"><a href="#【创建主题】" class="headerlink" title="【创建主题】"></a>【创建主题】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-topics.sh --zookeeper node3:2181 --create --topic spark_kafka --partitions 3 --replication-factor 1<br>kafka-topics.sh --zookeeper node3:2181 --list<br></code></pre></td></tr></table></figure><h3 id="【启动生产者和消费者】"><a href="#【启动生产者和消费者】" class="headerlink" title="【启动生产者和消费者】"></a>【启动生产者和消费者】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">kafka-console-producer.sh --broker-list node3:9092 --topic spark_kafka<br>kafka-console-consumer.sh --from-beginning --bootstrap-server node3:9092 --topic spark_kafka<br>kafka-console-consumer.sh --from-beginning --bootstrap-server node3:9092 --topic __consumer_offsets<br></code></pre></td></tr></table></figure><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="【启动spark-thriftserver】"><a href="#【启动spark-thriftserver】" class="headerlink" title="【启动spark-thriftserver】"></a>【启动spark-thriftserver】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">/<span class="hljs-built_in">export</span>/server/spark/sbin/start-thriftserver.sh \<br>  --hiveconf hive.server2.thrift.port=10001 \<br>  --hiveconf hive.server2.thrift.bind.host=node3 \<br>  --master <span class="hljs-built_in">local</span>[*]<br></code></pre></td></tr></table></figure><h3 id="【structured-Streaming】"><a href="#【structured-Streaming】" class="headerlink" title="【structured Streaming】"></a>【structured Streaming】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">--memory sink<br>CREATE TABLE db_spark.tb_word_count (<br>  id int NOT NULL AUTO_INCREMENT,<br>  word varchar(255) NOT NULL,<br>  count int NOT NULL,<br>  PRIMARY KEY (id),<br>  UNIQUE KEY word (word)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;<br><br>REPLACE INTO  tb_word_count (id, word, count) VALUES (NULL, ?, ?);<br></code></pre></td></tr></table></figure><h3 id="【spark-yarn-Pi】"><a href="#【spark-yarn-Pi】" class="headerlink" title="【spark yarn Pi】"></a>【spark yarn Pi】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">/<span class="hljs-built_in">export</span>/server/spark/bin/spark-submit \<br>--master yarn \<br>--class org.apache.spark.examples.SparkPi \<br><span class="hljs-variable">$&#123;SPARK_HOME&#125;</span>/examples/jars/spark-examples_2.11-2.4.5.jar \<br>10<br></code></pre></td></tr></table></figure><h3 id="【WordCount-yarn】"><a href="#【WordCount-yarn】" class="headerlink" title="【WordCount yarn】"></a>【WordCount yarn】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">/<span class="hljs-built_in">export</span>/server/spark/bin/spark-submit \<br>--master yarn \<br>--driver-memory 512m \<br>--executor-memory 512m \<br>--executor-cores 1 \<br>--num-executors 2 \<br>--queue default \<br>--class cn.itcast.spark._2SparkWordCount \<br>/opt/spark-chapter01-1.0-SNAPSHOT.jar<br></code></pre></td></tr></table></figure><h3 id="【Spark-submit】"><a href="#【Spark-submit】" class="headerlink" title="【Spark-submit】"></a>【Spark-submit】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs bash">【 Run application <span class="hljs-built_in">local</span> on 8 cores】<br>/<span class="hljs-built_in">export</span>/server/spark/bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master <span class="hljs-built_in">local</span>[8] \<br><span class="hljs-variable">$&#123;SPARK_HOME&#125;</span>/examples/jars/spark-examples_2.11-2.4.5.jar \<br>  100<br><br><span class="hljs-comment"># Run on a Spark standalone cluster in client deploy mode</span><br>./bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master spark://207.184.161.138:7077 \<br>  --executor-memory 20G \<br>  --total-executor-cores 100 \<br><span class="hljs-variable">$&#123;SPARK_HOME&#125;</span>/examples/jars/spark-examples_2.11-2.4.5.jar \<br>  1000<br><br><span class="hljs-comment"># Run on a Spark standalone cluster in cluster deploy mode with supervise</span><br>./bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master spark://207.184.161.138:7077 \<br>  --deploy-mode cluster \<br>  --supervise \<br>  --executor-memory 20G \<br>  --total-executor-cores 100 \<br>  /path/to/examples.jar \<br>  1000<br><br><span class="hljs-comment"># Run on a YARN cluster</span><br><span class="hljs-built_in">export</span> HADOOP_CONF_DIR=XXX<br>./bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master yarn \<br>  --deploy-mode cluster \  <span class="hljs-comment"># can be client for client mode</span><br>  --executor-memory 20G \<br>  --num-executors 50 \<br>  /path/to/examples.jar \<br>  1000<br><br><span class="hljs-comment"># Run a Python application on a Spark standalone cluster</span><br>./bin/spark-submit \<br>  --master spark://207.184.161.138:7077 \<br>  examples/src/main/python/pi.py \<br>  1000<br><br><span class="hljs-comment"># Run on a Mesos cluster in cluster deploy mode with supervise</span><br>./bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master mesos://207.184.161.138:7077 \<br>  --deploy-mode cluster \<br>  --supervise \<br>  --executor-memory 20G \<br>  --total-executor-cores 100 \<br>  http://path/to/examples.jar \<br>  1000<br><br><span class="hljs-comment"># Run on a Kubernetes cluster in cluster deploy mode</span><br>./bin/spark-submit \<br>  --class org.apache.spark.examples.SparkPi \<br>  --master k8s://xx.yy.zz.ww:443 \<br>  --deploy-mode cluster \<br>  --executor-memory 20G \<br>  --num-executors 50 \<br>  http://path/to/examples.jar \<br>  1000<br></code></pre></td></tr></table></figure><h2 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">sqoop import \<br>-D mapred.job.name=sqoop_import_dd_table  \<br>--connect <span class="hljs-string">&quot;jdbc:mysql://192.168.88.163:3306/insurance&quot;</span>  \<br>--username root  \<br>--password <span class="hljs-string">&quot;123456&quot;</span>  \<br>--table dd_table  \<br>--hive-import  \<br>--hive-database insurance  \<br>--hive-table dd_table  \<br>--hive-overwrite  \<br>-m 1  \<br>--fields-terminated-by <span class="hljs-string">&#x27;,&#x27;</span> \<br>--delete-target-dir<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>常用知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hive</tag>
      
      <tag>Kafka</tag>
      
      <tag>Spark</tag>
      
      <tag>Sqoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="/2020/08/24/first_post/"/>
    <url>/2020/08/24/first_post/</url>
    
    <content type="html"><![CDATA[<p>努力写博客, 总结经验教训, 学习永远在路上</p><h3 id="待完成的文章"><a href="#待完成的文章" class="headerlink" title="待完成的文章:"></a>待完成的文章:</h3><ul><li><input disabled="" type="checkbox"> 常用指令汇总</li><li><input disabled="" type="checkbox"> 开发环境搭建指南</li><li><input disabled="" type="checkbox"> 牛客网 SQL 刷题总结</li><li><input disabled="" type="checkbox"> 三级联动查询的思路</li><li><input disabled="" type="checkbox"> 拉链表的维护</li><li><input disabled="" type="checkbox"> 分析函数的使用</li><li><input disabled="" type="checkbox"> CAP原理解析</li><li><input disabled="" type="checkbox"> 项目开发当中的数据遗漏和数据倾斜问题</li></ul>]]></content>
    
    
    <categories>
      
      <category>基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开始</tag>
      
      <tag>计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
